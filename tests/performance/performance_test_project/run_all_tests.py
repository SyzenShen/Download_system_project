#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»æµ‹è¯•è„šæœ¬ - è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•
Main Test Runner - Execute All Performance Tests
"""

import os
import sys
import time
import json
import subprocess
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ è„šæœ¬è·¯å¾„
scripts_dir = os.path.join(os.path.dirname(__file__), 'scripts')
sys.path.append(scripts_dir)

from scripts.utils import TestLogger, ResultSaver, setup_test_environment, cleanup_test_environment

class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.logger = TestLogger("TestRunner")
        self.result_saver = ResultSaver()
        self.test_results = {}
        self.start_time = None
        self.end_time = None
        
        # æµ‹è¯•è„šæœ¬é…ç½®
        self.test_scripts = [
            {
                "name": "å•æ–‡ä»¶ä¸Šä¼ ä¸‹è½½é€Ÿåº¦æµ‹è¯•",
                "script": "single_file_test.py",
                "description": "æµ‹è¯•ä¸åŒå¤§å°æ–‡ä»¶çš„ä¸Šä¼ ä¸‹è½½æ€§èƒ½",
                "estimated_time": "30åˆ†é’Ÿ"
            },
            {
                "name": "å¹¶å‘æµ‹è¯•",
                "script": "concurrent_test.py", 
                "description": "æµ‹è¯•ä¸åŒå¹¶å‘çº§åˆ«ä¸‹çš„ç³»ç»Ÿæ€§èƒ½",
                "estimated_time": "45åˆ†é’Ÿ"
            },
            {
                "name": "æ–­ç‚¹ç»­ä¼ æµ‹è¯•",
                "script": "resume_test.py",
                "description": "æµ‹è¯•æ–­ç‚¹ç»­ä¼ åŠŸèƒ½çš„å¥å£®æ€§",
                "estimated_time": "20åˆ†é’Ÿ"
            },
            {
                "name": "èµ„æºç›‘æ§æµ‹è¯•",
                "script": "resource_monitor.py",
                "description": "ç›‘æ§ç³»ç»Ÿèµ„æºæ¶ˆè€—",
                "estimated_time": "15åˆ†é’Ÿ"
            },
            {
                "name": "åŸºçº¿å¯¹æ¯”æµ‹è¯•",
                "script": "baseline_comparison.py",
                "description": "ä¸ä¼ ç»Ÿå·¥å…·è¿›è¡Œæ€§èƒ½å¯¹æ¯”",
                "estimated_time": "25åˆ†é’Ÿ"
            },
            {
                "name": "å®‰å…¨æ€§åˆ†æ",
                "script": "security_analysis.py",
                "description": "è¿›è¡Œå®‰å…¨æ€§æ£€æµ‹å’Œåˆ†æ",
                "estimated_time": "10åˆ†é’Ÿ"
            },
            {
                "name": "éƒ¨ç½²æ¡ˆä¾‹æ¨¡æ‹Ÿ",
                "script": "deployment_simulation.py",
                "description": "æ¨¡æ‹ŸçœŸå®éƒ¨ç½²åœºæ™¯çš„ä½¿ç”¨ç»Ÿè®¡",
                "estimated_time": "5åˆ†é’Ÿ"
            }
        ]
    
    def run_single_test(self, test_config: Dict) -> Dict:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        test_name = test_config["name"]
        script_name = test_config["script"]
        script_path = os.path.join(scripts_dir, script_name)
        
        self.logger.info(f"å¼€å§‹è¿è¡Œæµ‹è¯•: {test_name}")
        self.logger.info(f"è„šæœ¬è·¯å¾„: {script_path}")
        self.logger.info(f"é¢„è®¡è€—æ—¶: {test_config['estimated_time']}")
        
        if not os.path.exists(script_path):
            error_msg = f"æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨: {script_path}"
            self.logger.error(error_msg)
            return {
                "status": "failed",
                "error": error_msg,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "duration_seconds": 0
            }
        
        # è®°å½•å¼€å§‹æ—¶é—´
        test_start = time.time()
        start_time = datetime.now()
        
        try:
            # è¿è¡Œæµ‹è¯•è„šæœ¬
            result = subprocess.run(
                [sys.executable, script_path],
                capture_output=True,
                text=True,
                timeout=3600,  # 1å°æ—¶è¶…æ—¶
                cwd=os.path.dirname(script_path)
            )
            
            # è®°å½•ç»“æŸæ—¶é—´
            test_end = time.time()
            end_time = datetime.now()
            duration = test_end - test_start
            
            if result.returncode == 0:
                self.logger.info(f"æµ‹è¯•å®Œæˆ: {test_name} (è€—æ—¶: {duration:.1f}ç§’)")
                
                # å°è¯•åŠ è½½æµ‹è¯•ç»“æœ
                test_result_data = self.load_test_result_data(test_name)
                
                return {
                    "status": "success",
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration_seconds": round(duration, 2),
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "test_data": test_result_data
                }
            else:
                error_msg = f"æµ‹è¯•å¤±è´¥: {test_name}, è¿”å›ç : {result.returncode}"
                self.logger.error(error_msg)
                self.logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                
                return {
                    "status": "failed",
                    "error": error_msg,
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration_seconds": round(duration, 2),
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode
                }
                
        except subprocess.TimeoutExpired:
            error_msg = f"æµ‹è¯•è¶…æ—¶: {test_name}"
            self.logger.error(error_msg)
            return {
                "status": "timeout",
                "error": error_msg,
                "start_time": start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "duration_seconds": 3600
            }
            
        except Exception as e:
            error_msg = f"æµ‹è¯•å¼‚å¸¸: {test_name}, é”™è¯¯: {str(e)}"
            self.logger.error(error_msg)
            return {
                "status": "error",
                "error": error_msg,
                "start_time": start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "duration_seconds": time.time() - test_start
            }
    
    def load_test_result_data(self, test_name: str) -> Optional[Dict]:
        """åŠ è½½æµ‹è¯•ç»“æœæ•°æ®"""
        try:
            # æ ¹æ®æµ‹è¯•åç§°æ¨æ–­ç»“æœæ–‡ä»¶
            result_files = {
                "å•æ–‡ä»¶ä¸Šä¼ ä¸‹è½½é€Ÿåº¦æµ‹è¯•": "single_file_speed_test_complete",
                "å¹¶å‘æµ‹è¯•": "concurrent_test_complete",
                "æ–­ç‚¹ç»­ä¼ æµ‹è¯•": "resume_test_complete", 
                "èµ„æºç›‘æ§æµ‹è¯•": "resource_monitor_complete",
                "åŸºçº¿å¯¹æ¯”æµ‹è¯•": "baseline_comparison_complete",
                "å®‰å…¨æ€§åˆ†æ": "security_analysis_complete",
                "éƒ¨ç½²æ¡ˆä¾‹æ¨¡æ‹Ÿ": "deployment_simulation_complete"
            }
            
            result_key = result_files.get(test_name)
            if result_key:
                return self.result_saver.load_test_result(result_key)
            
        except Exception as e:
            self.logger.warning(f"æ— æ³•åŠ è½½æµ‹è¯•ç»“æœæ•°æ®: {test_name}, é”™è¯¯: {e}")
        
        return None
    
    def run_all_tests(self) -> Dict:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.logger.info("å¼€å§‹è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•")
        self.start_time = datetime.now()
        
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        try:
            setup_test_environment()
            self.logger.info("æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
        except Exception as e:
            self.logger.error(f"æµ‹è¯•ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            return {"status": "failed", "error": f"ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}"}
        
        # è¿è¡Œæ¯ä¸ªæµ‹è¯•
        for i, test_config in enumerate(self.test_scripts, 1):
            test_name = test_config["name"]
            
            print(f"\n{'='*60}")
            print(f"è¿è¡Œæµ‹è¯• {i}/{len(self.test_scripts)}: {test_name}")
            print(f"æè¿°: {test_config['description']}")
            print(f"é¢„è®¡è€—æ—¶: {test_config['estimated_time']}")
            print(f"{'='*60}")
            
            # è¿è¡Œæµ‹è¯•
            test_result = self.run_single_test(test_config)
            self.test_results[test_name] = {
                **test_config,
                **test_result
            }
            
            # æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦
            if test_result["status"] == "success":
                print(f"âœ… {test_name} - æˆåŠŸ (è€—æ—¶: {test_result['duration_seconds']:.1f}ç§’)")
            else:
                print(f"âŒ {test_name} - {test_result['status']}: {test_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        self.end_time = datetime.now()
        
        # ç”Ÿæˆæµ‹è¯•æ±‡æ€»
        test_summary = self.generate_test_summary()
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        complete_results = {
            "test_summary": test_summary,
            "individual_tests": self.test_results,
            "execution_info": {
                "start_time": self.start_time.isoformat(),
                "end_time": self.end_time.isoformat(),
                "total_duration_seconds": (self.end_time - self.start_time).total_seconds(),
                "python_version": sys.version,
                "platform": sys.platform
            }
        }
        
        self.result_saver.save_test_result("all_tests_complete", complete_results)
        
        # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        try:
            cleanup_test_environment()
            self.logger.info("æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")
        except Exception as e:
            self.logger.warning(f"æµ‹è¯•ç¯å¢ƒæ¸…ç†å¤±è´¥: {e}")
        
        self.logger.info("æ‰€æœ‰æµ‹è¯•è¿è¡Œå®Œæˆ")
        return complete_results
    
    def generate_test_summary(self) -> Dict:
        """ç”Ÿæˆæµ‹è¯•æ±‡æ€»"""
        total_tests = len(self.test_results)
        successful_tests = sum(1 for result in self.test_results.values() if result.get("status") == "success")
        failed_tests = total_tests - successful_tests
        
        total_duration = (self.end_time - self.start_time).total_seconds()
        
        # ç»Ÿè®¡å„æµ‹è¯•çš„è€—æ—¶
        test_durations = {}
        for test_name, result in self.test_results.items():
            test_durations[test_name] = result.get("duration_seconds", 0)
        
        return {
            "overview": {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "failed_tests": failed_tests,
                "success_rate": round((successful_tests / total_tests) * 100, 1) if total_tests > 0 else 0,
                "total_duration_seconds": round(total_duration, 2),
                "total_duration_formatted": self.format_duration(total_duration)
            },
            "test_durations": test_durations,
            "failed_tests": [
                {
                    "name": name,
                    "error": result.get("error", "æœªçŸ¥é”™è¯¯"),
                    "status": result.get("status", "unknown")
                }
                for name, result in self.test_results.items()
                if result.get("status") != "success"
            ]
        }
    
    def format_duration(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æŒç»­æ—¶é—´"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        if hours > 0:
            return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ{secs}ç§’"
        elif minutes > 0:
            return f"{minutes}åˆ†é’Ÿ{secs}ç§’"
        else:
            return f"{secs}ç§’"
    
    def print_final_summary(self, results: Dict):
        """æ‰“å°æœ€ç»ˆæ±‡æ€»"""
        print(f"\n{'='*80}")
        print("æµ‹è¯•è¿è¡Œå®Œæˆ - æœ€ç»ˆæ±‡æ€»")
        print(f"{'='*80}")
        
        summary = results["test_summary"]["overview"]
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"  æˆåŠŸæµ‹è¯•: {summary['successful_tests']}")
        print(f"  å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
        print(f"  æˆåŠŸç‡: {summary['success_rate']}%")
        print(f"  æ€»è€—æ—¶: {summary['total_duration_formatted']}")
        
        if summary['failed_tests'] > 0:
            print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
            for failed_test in results["test_summary"]["failed_tests"]:
                print(f"  - {failed_test['name']}: {failed_test['error']}")
        
        print(f"\nâ±ï¸  å„æµ‹è¯•è€—æ—¶:")
        for test_name, duration in results["test_summary"]["test_durations"].items():
            status = "âœ…" if self.test_results[test_name].get("status") == "success" else "âŒ"
            print(f"  {status} {test_name}: {self.format_duration(duration)}")
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {self.result_saver.results_dir}")
        print(f"ğŸ“‹ æµ‹è¯•æŠ¥å‘Šå°†ç”Ÿæˆåˆ°: readme_test æ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    try:
        print("ğŸš€ å¼€å§‹è¿è¡Œæ–‡ä»¶ä¼ è¾“ç³»ç»Ÿæ€§èƒ½æµ‹è¯•å¥—ä»¶")
        print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
        runner = TestRunner()
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results = runner.run_all_tests()
        
        # æ‰“å°æœ€ç»ˆæ±‡æ€»
        runner.print_final_summary(results)
        
        return 0 if results["test_summary"]["overview"]["failed_tests"] == 0 else 1
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        print(f"\n\nğŸ’¥ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit(main())